{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/charles/anaconda3/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in /Users/charles/anaconda3/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: tqdm in /Users/charles/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: scipy in /Users/charles/anaconda3/lib/python3.11/site-packages (1.11.4)\n",
      "Requirement already satisfied: filelock in /Users/charles/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/charles/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/charles/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/charles/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/charles/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/charles/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /Users/charles/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/charles/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/charles/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/charles/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselTorch_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "100%|█████████████| 938/938 [00:04<00:00, 234.44it/s, accuracy=0.406, loss=1.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.87021499834081, Train Accuracy: 0.2996568496801706, Val Loss: 1.716408386351956, Val Accuracy: 0.3206608280254777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:03<00:00, 244.35it/s, accuracy=0.562, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.499628776044988, Train Accuracy: 0.476529184434968, Val Loss: 1.328058517662583, Val Accuracy: 0.5308519108280255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 938/938 [00:03<00:00, 239.72it/s, accuracy=0.5, loss=1.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.2260652352879042, Train Accuracy: 0.5944329690831557, Val Loss: 1.0983463013248078, Val Accuracy: 0.6385350318471338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:03<00:00, 261.73it/s, accuracy=0.75, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.0376472146526328, Train Accuracy: 0.6727245469083155, Val Loss: 0.9103060645662295, Val Accuracy: 0.7292993630573248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:03<00:00, 256.07it/s, accuracy=0.719, loss=0.872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.9184473901669353, Train Accuracy: 0.7120035980810234, Val Loss: 0.8273504148622987, Val Accuracy: 0.7497014331210191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:03<00:00, 255.13it/s, accuracy=0.688, loss=0.864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.8208027053743537, Train Accuracy: 0.7485840884861408, Val Loss: 0.7452503957186535, Val Accuracy: 0.7772691082802548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:03<00:00, 240.82it/s, accuracy=0.656, loss=0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.7574538363576698, Train Accuracy: 0.7685567697228145, Val Loss: 0.6940304759391553, Val Accuracy: 0.8030453821656051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:03<00:00, 244.04it/s, accuracy=0.625, loss=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.721475255959578, Train Accuracy: 0.7782016257995735, Val Loss: 0.7495489970893617, Val Accuracy: 0.7504976114649682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:03<00:00, 251.27it/s, accuracy=0.844, loss=0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.687601710973518, Train Accuracy: 0.7893123667377399, Val Loss: 0.6800394685594899, Val Accuracy: 0.7861265923566879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:03<00:00, 248.54it/s, accuracy=0.812, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.6703090688376538, Train Accuracy: 0.7936433901918977, Val Loss: 0.6135912938102795, Val Accuracy: 0.8184713375796179\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=1.0):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselTorch_rbf(self, distances):\n",
    "        return torch.special.bessel_j0(self.alpha * distances)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselTorch_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselScipy_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "100%|█████████████| 938/938 [00:05<00:00, 162.57it/s, accuracy=0.406, loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.8568752814711793, Train Accuracy: 0.29907382729211085, Val Loss: 1.68206569267686, Val Accuracy: 0.3922173566878981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 155.55it/s, accuracy=0.531, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.5072906341379895, Train Accuracy: 0.47333089019189767, Val Loss: 1.3003853119103013, Val Accuracy: 0.5588176751592356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 155.09it/s, accuracy=0.656, loss=1.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.180981670043616, Train Accuracy: 0.6121735074626866, Val Loss: 1.0423499957011764, Val Accuracy: 0.6480891719745223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 164.61it/s, accuracy=0.781, loss=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.9940195738760902, Train Accuracy: 0.6775053304904051, Val Loss: 0.8962098659983107, Val Accuracy: 0.7236265923566879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:06<00:00, 154.22it/s, accuracy=0.688, loss=0.958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.8852014968644327, Train Accuracy: 0.7174173773987207, Val Loss: 0.8240200844919605, Val Accuracy: 0.7423367834394905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 938/938 [00:05<00:00, 160.47it/s, accuracy=0.781, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.8188450021911532, Train Accuracy: 0.7373400852878464, Val Loss: 0.7476661201495274, Val Accuracy: 0.7688097133757962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 165.31it/s, accuracy=0.75, loss=0.692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.7679368628304142, Train Accuracy: 0.7552305437100213, Val Loss: 0.7876296681203659, Val Accuracy: 0.7270103503184714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 160.05it/s, accuracy=0.812, loss=0.678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.7364979100697584, Train Accuracy: 0.7658582089552238, Val Loss: 0.6932593658091916, Val Accuracy: 0.7631369426751592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 159.48it/s, accuracy=0.906, loss=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.7100324122064403, Train Accuracy: 0.7737040245202559, Val Loss: 0.645116623419865, Val Accuracy: 0.7990644904458599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:06<00:00, 145.65it/s, accuracy=0.719, loss=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.6788152822934742, Train Accuracy: 0.7879297707889126, Val Loss: 0.6776232677660171, Val Accuracy: 0.7826433121019108\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import scipy.special as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=1.0, n=0):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.n = n # order of bessel function\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselScipy_rbf(self, distances):\n",
    "        # Detach the tensor from the computation graph and convert to NumPy array\n",
    "        distances_np = distances.detach().numpy()\n",
    "        # Compute the Bessel function\n",
    "        bessel_values = sc.jn(self.n, self.alpha * distances_np)\n",
    "        # Convert back to PyTorch tensor\n",
    "        return torch.from_numpy(bessel_values)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselScipy_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Yukawa function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:04<00:00, 194.14it/s, accuracy=0.156, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.3025851272570805, Train Accuracy: 0.09683168976545842, Val Loss: 2.3025851143393545, Val Accuracy: 0.09723328025477707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:04<00:00, 207.91it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.3025850232984464, Train Accuracy: 0.09929704157782517, Val Loss: 2.3025849032553896, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:04<00:00, 199.32it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 2.3025847869132883, Train Accuracy: 0.09869736140724947, Val Loss: 2.3025846147233513, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:04<00:00, 200.85it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.302583869586367, Train Accuracy: 0.09869736140724947, Val Loss: 2.302582263946533, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:04<00:00, 202.27it/s, accuracy=0.156, loss=2.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 2.2849717795975937, Train Accuracy: 0.09874733475479744, Val Loss: 2.1963904830300884, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 199.35it/s, accuracy=0.0625, loss=2.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 2.162391730335984, Train Accuracy: 0.09869736140724947, Val Loss: 2.144921908712691, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 196.72it/s, accuracy=0.0625, loss=2.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 2.1342803308450335, Train Accuracy: 0.09869736140724947, Val Loss: 2.127809716637727, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 198.81it/s, accuracy=0.0312, loss=2.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.120784513985933, Train Accuracy: 0.09868070362473348, Val Loss: 2.1170110861966562, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 938/938 [00:04<00:00, 197.25it/s, accuracy=0.125, loss=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 2.1115353395943957, Train Accuracy: 0.09873067697228145, Val Loss: 2.109226473577463, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 198.87it/s, accuracy=0.0312, loss=2.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 2.1038026725813777, Train Accuracy: 0.09868070362473348, Val Loss: 2.1012363130119955, Val Accuracy: 0.09783041401273886\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=0.5, beta=1.0):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def yukawa_rbf(self, distances):\n",
    "        return (self.beta / distances) * torch.exp(-self.alpha * distances)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.yukawa_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### yukawa_rbf when beta value is greater than alpha by a huge difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 191.59it/s, accuracy=0.812, loss=0.595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.596172207771842, Train Accuracy: 0.46095415778251597, Val Loss: 0.6992951026008387, Val Accuracy: 0.7898089171974523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 185.18it/s, accuracy=0.875, loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.561266076828498, Train Accuracy: 0.8400852878464818, Val Loss: 0.4426335073105849, Val Accuracy: 0.8748009554140127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 193.44it/s, accuracy=0.812, loss=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.40958247661018676, Train Accuracy: 0.8862440031982942, Val Loss: 0.3550494434252666, Val Accuracy: 0.8974920382165605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 189.86it/s, accuracy=0.969, loss=0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.34617711991262334, Train Accuracy: 0.902318763326226, Val Loss: 0.3097242308650047, Val Accuracy: 0.9105294585987261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 189.85it/s, accuracy=0.938, loss=0.371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.3075347076902893, Train Accuracy: 0.9129964019189766, Val Loss: 0.27957596540878155, Val Accuracy: 0.9186902866242038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 188.49it/s, accuracy=0.969, loss=0.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.27913960023348267, Train Accuracy: 0.9212253464818764, Val Loss: 0.2553291678499834, Val Accuracy: 0.9259554140127388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:04<00:00, 197.32it/s, accuracy=0.938, loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.256848146539253, Train Accuracy: 0.9270389125799574, Val Loss: 0.23541942690232187, Val Accuracy: 0.9326234076433121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:04<00:00, 192.17it/s, accuracy=0.844, loss=0.444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.2388445749513503, Train Accuracy: 0.9326359275053305, Val Loss: 0.2221835786654691, Val Accuracy: 0.934812898089172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 938/938 [00:04<00:00, 198.79it/s, accuracy=1, loss=0.0635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.2236059221393391, Train Accuracy: 0.9369003198294243, Val Loss: 0.20893652722903877, Val Accuracy: 0.9408837579617835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 185.39it/s, accuracy=0.906, loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.21059394469345682, Train Accuracy: 0.9409814765458422, Val Loss: 0.20094871865644767, Val Accuracy: 0.9410828025477707\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=0.2, beta=10):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def yukawa_rbf(self, distances):\n",
    "        return (self.beta / distances) * torch.exp(-self.alpha * distances)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.yukawa_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselScipy_rbf when n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 143.96it/s, accuracy=0.188, loss=2.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.2611518719557253, Train Accuracy: 0.13919243070362472, Val Loss: 2.179722252924731, Val Accuracy: 0.14639729299363058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████| 938/938 [00:06<00:00, 151.57it/s, accuracy=0.25, loss=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.0673088154304766, Train Accuracy: 0.23051039445628999, Val Loss: 1.9820359755473531, Val Accuracy: 0.2770700636942675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 147.12it/s, accuracy=0.406, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.963187652228992, Train Accuracy: 0.26724080490405117, Val Loss: 1.9250115353590365, Val Accuracy: 0.3092157643312102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 152.62it/s, accuracy=0.438, loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.9252259572431731, Train Accuracy: 0.28519789445628996, Val Loss: 1.8935781785636951, Val Accuracy: 0.2880175159235669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 151.45it/s, accuracy=0.375, loss=1.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 1.900750492300306, Train Accuracy: 0.2957256130063966, Val Loss: 1.9287402007230527, Val Accuracy: 0.3209593949044586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:07<00:00, 127.16it/s, accuracy=0.375, loss=1.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 1.886056650422021, Train Accuracy: 0.3101512526652452, Val Loss: 1.8659079105231413, Val Accuracy: 0.30851910828025475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 140.00it/s, accuracy=0.219, loss=2.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 1.8666329957020562, Train Accuracy: 0.32387726545842216, Val Loss: 1.8522085908112254, Val Accuracy: 0.33479299363057324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:06<00:00, 143.68it/s, accuracy=0.25, loss=1.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.8476072388417177, Train Accuracy: 0.3414678837953092, Val Loss: 1.8129395740047383, Val Accuracy: 0.381468949044586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 148.79it/s, accuracy=0.344, loss=1.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 1.825779037816184, Train Accuracy: 0.3519789445628998, Val Loss: 1.7967256808736523, Val Accuracy: 0.35201035031847133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 148.02it/s, accuracy=0.438, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 1.8008560168463539, Train Accuracy: 0.36468883262260127, Val Loss: 1.8136734468921734, Val Accuracy: 0.3414609872611465\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import scipy.special as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=1.0, n=1):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.n = n # order of bessel function\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselScipy_rbf(self, distances):\n",
    "        # Detach the tensor from the computation graph and convert to NumPy array\n",
    "        distances_np = distances.detach().numpy()\n",
    "        # Compute the Bessel function\n",
    "        bessel_values = sc.jn(self.n, self.alpha * distances_np)\n",
    "        # Convert back to PyTorch tensor\n",
    "        return torch.from_numpy(bessel_values)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselScipy_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselScipy_rbf when n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 151.18it/s, accuracy=0.344, loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.8216468393167198, Train Accuracy: 0.31378264925373134, Val Loss: 1.5644996879966395, Val Accuracy: 0.4394904458598726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 152.44it/s, accuracy=0.719, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.385536540291711, Train Accuracy: 0.5268190298507462, Val Loss: 1.1438822700719165, Val Accuracy: 0.6559514331210191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 154.17it/s, accuracy=0.875, loss=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.0703157580483442, Train Accuracy: 0.6546008795309168, Val Loss: 0.9227082915366835, Val Accuracy: 0.7136743630573248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:06<00:00, 151.31it/s, accuracy=0.656, loss=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.904788317837949, Train Accuracy: 0.712853144989339, Val Loss: 0.8441161953719558, Val Accuracy: 0.7079020700636943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:07<00:00, 128.71it/s, accuracy=0.719, loss=0.834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.8073424843074416, Train Accuracy: 0.746068763326226, Val Loss: 0.7917468697781775, Val Accuracy: 0.7528861464968153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:06<00:00, 145.66it/s, accuracy=0.812, loss=0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.7381506396699816, Train Accuracy: 0.7729211087420043, Val Loss: 0.6883984261257633, Val Accuracy: 0.7840366242038217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:07<00:00, 120.00it/s, accuracy=0.906, loss=0.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.6956801519655724, Train Accuracy: 0.783315565031983, Val Loss: 0.645060041717663, Val Accuracy: 0.8021496815286624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:06<00:00, 146.83it/s, accuracy=0.906, loss=0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6651310545485666, Train Accuracy: 0.7943097014925373, Val Loss: 0.689323677948326, Val Accuracy: 0.7765724522292994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 150.01it/s, accuracy=0.781, loss=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.6381083912432575, Train Accuracy: 0.804670842217484, Val Loss: 0.5864686185766936, Val Accuracy: 0.8277269108280255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 134.04it/s, accuracy=0.75, loss=0.676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.6185251129652137, Train Accuracy: 0.8094849413646056, Val Loss: 0.5913325276724093, Val Accuracy: 0.8154856687898089\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import scipy.special as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=1.0, n=2):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.n = n # order of bessel function\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselScipy_rbf(self, distances):\n",
    "        # Detach the tensor from the computation graph and convert to NumPy array\n",
    "        distances_np = distances.detach().numpy()\n",
    "        # Compute the Bessel function\n",
    "        bessel_values = sc.jn(self.n, self.alpha * distances_np)\n",
    "        # Convert back to PyTorch tensor\n",
    "        return torch.from_numpy(bessel_values)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselScipy_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselScipy_rbf when n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 140.73it/s, accuracy=0.188, loss=2.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.293046501653789, Train Accuracy: 0.11343949893390191, Val Loss: 2.2744884642825762, Val Accuracy: 0.11375398089171974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 938/938 [00:06<00:00, 138.44it/s, accuracy=0.25, loss=2.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.2274325641233528, Train Accuracy: 0.1470882196162047, Val Loss: 2.1791342048887996, Val Accuracy: 0.16192277070063693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 135.25it/s, accuracy=0.281, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 2.158265300396917, Train Accuracy: 0.18700026652452026, Val Loss: 2.1349693901219946, Val Accuracy: 0.18740047770700638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 142.85it/s, accuracy=0.281, loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.1289260505613234, Train Accuracy: 0.19871068763326227, Val Loss: 2.113569215604454, Val Accuracy: 0.20003980891719744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 137.81it/s, accuracy=0.312, loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 2.1165375844247816, Train Accuracy: 0.2023420842217484, Val Loss: 2.104306097243242, Val Accuracy: 0.20431926751592358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:07<00:00, 121.16it/s, accuracy=0.312, loss=1.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 2.109882681227442, Train Accuracy: 0.2039079157782516, Val Loss: 2.0974174859417474, Val Accuracy: 0.2041202229299363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:07<00:00, 126.90it/s, accuracy=0.219, loss=1.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 2.106141815942996, Train Accuracy: 0.20452425373134328, Val Loss: 2.0936358430583004, Val Accuracy: 0.2044187898089172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:06<00:00, 147.77it/s, accuracy=0.25, loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.103309626518282, Train Accuracy: 0.20492404051172708, Val Loss: 2.091101906861469, Val Accuracy: 0.2047173566878981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 145.20it/s, accuracy=0.219, loss=2.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 2.1015117198927826, Train Accuracy: 0.2052738539445629, Val Loss: 2.09147314964586, Val Accuracy: 0.20591162420382167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:06<00:00, 145.91it/s, accuracy=0.281, loss=2.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 2.0987612014132013, Train Accuracy: 0.20545708955223882, Val Loss: 2.0891462374644676, Val Accuracy: 0.20451831210191082\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import scipy.special as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=1.0, n=3):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.n = n # order of bessel function\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselScipy_rbf(self, distances):\n",
    "        # Detach the tensor from the computation graph and convert to NumPy array\n",
    "        distances_np = distances.detach().numpy()\n",
    "        # Compute the Bessel function\n",
    "        bessel_values = sc.jn(self.n, self.alpha * distances_np)\n",
    "        # Convert back to PyTorch tensor\n",
    "        return torch.from_numpy(bessel_values)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselScipy_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselScipy_rbf when n=2 and alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:05<00:00, 170.15it/s, accuracy=0.125, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.3037120317345234, Train Accuracy: 0.09918043710021322, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 177.02it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.3025851249694824, Train Accuracy: 0.09869736140724947, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 180.84it/s, accuracy=0.0938, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 2.3025851249694824, Train Accuracy: 0.09871401918976545, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 177.81it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 2.3025851249694824, Train Accuracy: 0.09869736140724947, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:05<00:00, 175.48it/s, accuracy=0.188, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 2.3025851249694824, Train Accuracy: 0.09876399253731344, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████| 938/938 [00:05<00:00, 176.93it/s, accuracy=0, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 2.3025851249694824, Train Accuracy: 0.09866404584221748, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 174.31it/s, accuracy=0.0938, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 2.3025851249694824, Train Accuracy: 0.09871401918976545, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 179.13it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 2.3025851249694824, Train Accuracy: 0.09869736140724947, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 179.06it/s, accuracy=0.0625, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 2.3025851249694824, Train Accuracy: 0.09869736140724947, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:05<00:00, 166.69it/s, accuracy=0.156, loss=2.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 2.3025851249694824, Train Accuracy: 0.09874733475479744, Val Loss: 2.302585126488072, Val Accuracy: 0.09783041401273886\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import scipy.special as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=0.1, n=2):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.n = n # order of bessel function\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselScipy_rbf(self, distances):\n",
    "        # Detach the tensor from the computation graph and convert to NumPy array\n",
    "        distances_np = distances.detach().numpy()\n",
    "        # Compute the Bessel function\n",
    "        bessel_values = sc.jn(self.n, self.alpha * distances_np)\n",
    "        # Convert back to PyTorch tensor\n",
    "        return torch.from_numpy(bessel_values)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselScipy_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BesselScipy_rbf when n=2 and alpha = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 162.25it/s, accuracy=0.656, loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.64636694673282, Train Accuracy: 0.45362473347547977, Val Loss: 1.1378585684830975, Val Accuracy: 0.6636146496815286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 938/938 [00:05<00:00, 161.05it/s, accuracy=0.75, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.9869466598099991, Train Accuracy: 0.7000099946695096, Val Loss: 0.848231544919834, Val Accuracy: 0.7459195859872612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 160.67it/s, accuracy=0.875, loss=0.475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.8121030008170143, Train Accuracy: 0.7560800906183369, Val Loss: 0.751132014830401, Val Accuracy: 0.7727906050955414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 159.09it/s, accuracy=0.656, loss=0.925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.7310588115186833, Train Accuracy: 0.7810167910447762, Val Loss: 0.6974633165225861, Val Accuracy: 0.790406050955414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 166.33it/s, accuracy=0.844, loss=0.543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.68068932930925, Train Accuracy: 0.7965751599147122, Val Loss: 0.6627962190634126, Val Accuracy: 0.7965764331210191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 161.17it/s, accuracy=0.844, loss=0.647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.6477712572637652, Train Accuracy: 0.8052538646055437, Val Loss: 0.6249354643047236, Val Accuracy: 0.8105095541401274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:06<00:00, 153.49it/s, accuracy=0.719, loss=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.622089531630087, Train Accuracy: 0.8151319296375267, Val Loss: 0.612149286801648, Val Accuracy: 0.810609076433121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 168.01it/s, accuracy=0.719, loss=0.709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6003978619062061, Train Accuracy: 0.8217783848614072, Val Loss: 0.582731483563496, Val Accuracy: 0.8192675159235668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 938/938 [00:05<00:00, 169.06it/s, accuracy=0.781, loss=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.5822623589717503, Train Accuracy: 0.825992803837953, Val Loss: 0.569099146849031, Val Accuracy: 0.8298168789808917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████| 938/938 [00:05<00:00, 167.52it/s, accuracy=0.844, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.5674075498255585, Train Accuracy: 0.8325559701492538, Val Loss: 0.5668013189818449, Val Accuracy: 0.8303144904458599\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import scipy.special as sc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class RBFBANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_centers, alpha=10, n=2):\n",
    "        super(RBFBANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        self.alpha = alpha\n",
    "        self.n = n # order of bessel function\n",
    "\n",
    "        self.centers = nn.Parameter(torch.empty(num_centers, input_dim))\n",
    "        init.xavier_uniform_(self.centers)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.empty(num_centers, output_dim))\n",
    "        init.xavier_uniform_(self.weights)\n",
    "\n",
    "    def besselScipy_rbf(self, distances):\n",
    "        # Detach the tensor from the computation graph and convert to NumPy array\n",
    "        distances_np = distances.detach().numpy()\n",
    "        # Compute the Bessel function\n",
    "        bessel_values = sc.jn(self.n, self.alpha * distances_np)\n",
    "        # Convert back to PyTorch tensor\n",
    "        return torch.from_numpy(bessel_values)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distances = torch.cdist(x, self.centers)\n",
    "        basis_values = self.besselScipy_rbf(distances)\n",
    "        output = torch.sum(basis_values.unsqueeze(2) * self.weights.unsqueeze(0), dim=1)\n",
    "        return output\n",
    "class RBFBAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers):\n",
    "        super(RBFBAN, self).__init__()\n",
    "        self.rbf_ban_layer = RBFBANLayer(input_dim, hidden_dim, num_centers)\n",
    "        self.output_weights = nn.Parameter(torch.empty(hidden_dim, output_dim))\n",
    "        init.xavier_uniform_(self.output_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rbf_ban_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.matmul(x, self.output_weights)\n",
    "        return x\n",
    "\n",
    "# Load MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "valset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "model = RBFBAN(28 * 28, 64, 10, num_centers=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define ReduceLROnPlateau scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with tqdm(trainloader) as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "            total_loss += loss.item()\n",
    "            total_accuracy += accuracy.item()\n",
    "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n",
    "    total_loss /= len(trainloader)\n",
    "    total_accuracy /= len(trainloader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.view(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "    val_loss /= len(valloader)\n",
    "    val_accuracy /= len(valloader)\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
